{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning\n",
    "\n",
    "In this notebook, we will guide you through the first steps and basic concepts of Deep Learning.\n",
    "\n",
    "For this purpose, we will use an API called Keras, running on top of a library called TensorFlow. You may find Keras documentation at https://keras.io/.\n",
    "\n",
    "We are going to use a well-known dataset called CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html), which consists of 60k 32x32 color images labeled in 10 classes. Throughout this notebook, you will be guided in the design of deep neural network classifiers for this dataset, with increasing complexity and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "num_classes = 10\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's visualize some examples of each class\n",
    "labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "num_rows = 5\n",
    "plt.figure(figsize=(20,10))\n",
    "count = 0\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_classes):\n",
    "        class_mask = (y_train == j).reshape(-1)\n",
    "        count += 1\n",
    "        rnd_idx = np.random.choice(X_train[class_mask].shape[0])\n",
    "        img = (X_train[class_mask])[rnd_idx]\n",
    "        plt.subplot(num_rows,num_classes,count) \n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if i==0:\n",
    "            plt.title(labels[j])\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you should already know, besides the usual training and test sets, it is very useful to have a **validation set**.\n",
    "\n",
    "Images in the validation set are not used to train the model itself, but evaluating the model performance on those images is useful to choose the training hyperparameters (e.g.: model architecture, learning rate and number of training iterations).\n",
    "\n",
    "In the following cell, you should select `num_validation` samples from our training set and store them in new arrays `X_val` and `y_val`. These samples must be **removed** from the training set, so the size of the arrays `X_train` and `y_train` should change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_validation = 5000\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, you should implement the following preprocessing steps:\n",
    "\n",
    "1. Normalize the image pixel values to be in the range (0,1). They are currently in the range (0,255).\n",
    "2. Compute the mean training image and subtract it to all images in the training, validation and test sets.\n",
    "\n",
    "These are common preprocessing steps that you should follow prior to training any neural network that receives images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will design your first deep neural network! The architecture should be the following:\n",
    "\n",
    "1. Fully connected layer (a.k.a. dense layer) with 256 output neurons, followed by a ReLU non-linearity (https://en.wikipedia.org/wiki/Rectifier_(neural_networks).\n",
    "2. Fully connected layer with 128 output neurons, followed by ReLU.\n",
    "3. Fully connected layer with 32 output neurons, followed by ReLU.\n",
    "4. Fully connected layer followed by a softmax (https://en.wikipedia.org/wiki/Softmax_function), which outputs the probabilities for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_model = Sequential()\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides designing the network, we also need to define the function that it aims to minimize during training. Such function is usually called a **loss function**.\n",
    "\n",
    "In classification problems, the following loss function is frequently used:\n",
    "\n",
    "\\begin{equation}\n",
    "L(\\theta) = -\\sum_{i=1}^N \\log p(y_i | X_i , \\theta)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$ summarizes all the parameters in the neural network, $X_i$ and $y_i$, for $i=1,...,N$, are the training images and their ground-truth labels, respectively, and $p(k | X, \\theta)$ is the predicted probability that a given image $X$ belongs to the class $k$, according to the current parameters $\\theta$.\n",
    "\n",
    "This loss function is usually called **cross-entropy** (a.k.a. negative log-likelihood). You should define it in the following cell and call it `xen_loss`.\n",
    "\n",
    "**Question:** What is the loss value when the neural network gives 1.0 probability to the correct class for all images in the training set? And what is the loss value if it gives it 0.0 probability instead?\n",
    "\n",
    "Hint: Keras already has an implementation of this loss function, so you do not need to implement it by yourself. Search for it in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ultimate goal is to find the parameters $\\theta^*$ that minimize our loss, that is, we want to find:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^* = \\text{argmin}_ \\theta L(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "In practice, this is infeasible, so we'll be happy if we find at least a local minimum. The following iterative procedure is guaranteed to converge to a critical point (possibly a local minimum):\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta^{(t+1)} \\leftarrow \\theta^{(t)} + \\eta \\nabla_{\\theta} L(\\theta^{(t)}),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta$, called learning rate, should be kept small enough.\n",
    "\n",
    "This algorithm is called **gradient descent**. There are several variants to this algorithm that have better performance. Every deep learning library (like TensorFlow, PyTorch, Theano, etc.) is capable of computing the gradient $\\nabla_{\\theta} L(\\theta^{(t)})$ automatically and implements multiple variants of gradient descent. \n",
    "\n",
    "Keras calls **optimizer** to the algorithms of this type together with their hyperparameters (learning rate and possibly others). In the cell below, you should define an Adam optimizer with a learning rate of 1e-4. Call it `opt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's compile our model using the loss and optimizer we have defined\n",
    "fc_model.compile(loss=xen_loss,\n",
    "                 optimizer=opt,\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the neural network that we have defined consists of affine layers only. By definition, these layers receive as input a (flat) vector. However, our inputs are color images, which are naturally represented by 3-dimensional arrays. Therefore, we must flatten these arrays prior to training. \n",
    "\n",
    "This is what you should do in the following cell. Store the flattened arrays into new variables `X_train_flat`, `X_val_flat` and `X_test_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "#####################\n",
    "\n",
    "# Convert the labels to one-hot format\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're all set to train our network! You should call the function `fit()` below (check Keras documentation for details), training your network for the number of `epochs` and using the `batch_size` defined below.\n",
    "\n",
    "After training has finished, you should get a training accuracy of around 76% and a validation accuracy of almost 53%, which clearly indicates a significant overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you have seen, the performance of your model is far from being good. The main reason for this is the fact that the model was not designed to take advantage of the spatial structure of your input data (images).\n",
    "\n",
    "For this purpose, a special kind of layer, called **convolutional layer** has been designed. Neural networks containing at least one convolutional layer are called convolutional neural networks (or, abbrev., CNNs or ConvNets).\n",
    "\n",
    "In the following reference, you may find a very nice introduction about CNNs. If you are not yet familiar with CNNs, this is something that you **really** should read before continuing this exercise.\n",
    "\n",
    "http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Please complete the function `get_model_and_optimizer()`, defining a CNN with the following architecture:\n",
    "1. Conv. layer with 32 3x3 filters, followed by ReLU\n",
    "2. Conv. layer with 32 3x3 filters, followed by ReLU\n",
    "3. 2x2 Max Pooling layer\n",
    "4. Conv. layer with 64 3x3 filters, followed by ReLU\n",
    "5. Conv. layer with 64 3x3 filters, followed by ReLU\n",
    "6. 2x2 Max Pooling layer\n",
    "7. Fully connected layer with 512 output neurons, followed by ReLU\n",
    "8. Fully connected layer followed by softmax\n",
    "\n",
    "Your function should also return an optimizer, which can be identical to the one you created before.\n",
    "\n",
    "Hint: Note that, between the last conv. layer and the first fully connected layer, the input array must be flattened into a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_and_optimizer():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    ########################\n",
    "    \n",
    "    return model, opt\n",
    "\n",
    "cnn_model, opt = get_model_and_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's compile our model using the loss and optimizer we have defined\n",
    "cnn_model.compile(loss=xen_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our `cnn_model`. Note that, this time, you do not need to use the flattened inputs, because convolutional layers are designed to receive images in their original format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll try a technique called **dataset augmentation**, which is likely to further improve your results!\n",
    "\n",
    "This technique consists in applying transformations to your training images, creating new training instances and, therefore, increasing the number of examples in your training set. Multiple transformations may be applied, being  flipping the image and applying small rotations and/or translations to it the most common ones.\n",
    "\n",
    "Here, you'll be applying them randomly and on-the-fly, that is, new images will be generated during training. We suggest you apply the following transformations:\n",
    "\n",
    "1. Horizontal flipping.\n",
    "2. Horizontal shift by a fraction of 0.1 of the total width.\n",
    "3. Vertical shift by a fraction of 0.1 of the total width.\n",
    "\n",
    "Hint: check `ImageDataGenerator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ### \n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are augmenting data on-the-fly, we need to pass our data generator to the fitting routine. You should do this in the cell below.\n",
    "\n",
    "Hint: check `fit_generator()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model, opt = get_model_and_optimizer() # re-initialize the model and the optimizer\n",
    "\n",
    "cnn_model.compile(loss=xen_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll evaluate the performance of our best model in the test set. Complete the cell below, saving the test loss and accuracy in the array `scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "######################\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
